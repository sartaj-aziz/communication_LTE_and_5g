# -*- coding: utf-8 -*-
"""Communication_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16-SUj7tApWuQnXg4nHg6gLKCWJBogaKM

### Channel Estimation with Convolutional Neural Network

### connecting google drive to colab
"""

from google.colab import drive
drive.mount('/content/drive')

"""### scipy is used for loading .mat format dataset"""

import scipy.io

perfect=scipy.io.loadmat('/content/drive/MyDrive/deep_mimo_dataset/Perfect_H_40000.mat')['My_perfect_H']

noisy_input_12=scipy.io.loadmat('/content/drive/MyDrive/deep_mimo_dataset/My_noisy_H_12.mat')

noisy_input=scipy.io.loadmat('/content/drive/MyDrive/deep_mimo_dataset/My_noisy_H_22.mat')['My_noisy_H']

"""### printing 4d dataset"""

print(noisy_input)

"""### logging information"""

import logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s | %(process)d | %(name)s | %(levelname)s:  %(message)s',
                    datefmt='%d/%b/%Y - %H:%M:%S')

logger = logging.getLogger(__name__)
print(logger)

"""### Size and shape of the dataset"""

print(noisy_input.shape)

import numpy as np

"""### Analysis of interpolation"""

idx = [14 * i for i in range(1, 72, 6)] + [4 + 14 * i for i in range(4, 72, 6)] + \
              [7 + 14 * i for i in range(1, 72, 6)] + [11 + 14 * i for i in range(4, 72, 6)]
print(idx)

r=[x//14 for x in idx]
c=[x%14 for x in idx]
print(r)
print(c)
q=zip(r,c)
print(set(q))

"""###Import packages"""

import numpy as np
import math
from keras.models import Sequential,  Model
from keras.layers import Convolution2D,Input,BatchNormalization,Conv2D,Activation,Lambda,Subtract,Conv2DTranspose, PReLU
from keras.regularizers import l2
from keras.layers import  Reshape,Dense,Flatten
from keras.callbacks import ModelCheckpoint
from keras.optimizers import SGD, Adam
from scipy.io import loadmat
import keras.backend as K
from keras.callbacks import ModelCheckpoint
from keras.optimizers import SGD, Adam
import numpy as np
import math
from scipy import interpolate

"""### calculating Peak signal to noise ratio"""

def psnr(target, ref):
    # assume RGB image
    target_data = np.array(target, dtype=float)
    ref_data = np.array(ref, dtype=float)

    diff = ref_data - target_data
    diff = diff.flatten('C')

    rmse = math.sqrt(np.mean(diff ** 2.))

    return 20 * math.log10(255. / rmse)

"""### Function of interpolation
#### reference: LTE documatation for pilot symbol
"""

def interpolation(noisy , SNR , Number_of_pilot , interp):
    noisy_image = np.zeros((40000,72,14,2))

    noisy_image[:,:,:,0] = np.real(noisy)
    noisy_image[:,:,:,1] = np.imag(noisy)

    idx=[]


    if (Number_of_pilot == 48):
        idx = [14*i for i in range(1, 72,6)]+[4+14*i for i in range(4, 72,6)]+[7+14*i for i in range(1, 72,6)]+[11+14*i for i in range(4, 72,6)]
    elif (Number_of_pilot == 16):
        idx= [4+14*i for i in range(1, 72,9)]+[9+14*i for i in range(4, 72,9)]
    elif (Number_of_pilot == 24):
        idx = [14*i for i in range(1,72,9)]+ [6+14*i for i in range(4,72,9)]+ [11+14*i for i in range(1,72,9)]
    elif (Number_of_pilot == 8):
      idx = [4+14*i for  i in range(5,72,18)]+[9+14*i for i in range(8,72,18)]
    elif (Number_of_pilot == 36):
      idx = [14*i for  i in range(1,72,6)]+[6+14*i for i in range(4,72,6)] + [11+14*i for i in range(1,72,6)]



    r = [x//14 for x in idx]
    c = [x%14 for x in idx]



    interp_noisy = np.zeros((40000,72,14,2))

    for i in range(len(noisy)):
        z = [noisy_image[i,j,k,0] for j,k in zip(r,c)]
        if(interp == 'rbf'):
            f = interpolate.Rbf(np.array(r).astype(float), np.array(c).astype(float), z,function='gaussian')
            X , Y = np.meshgrid(range(72),range(14))
            z_intp = f(X, Y)
            interp_noisy[i,:,:,0] = z_intp.T
        elif(interp == 'spline'):
            tck = interpolate.bisplrep(np.array(r).astype(float), np.array(c).astype(float), z)
            z_intp = interpolate.bisplev(range(72),range(14),tck)
            interp_noisy[i,:,:,0] = z_intp
        z = [noisy_image[i,j,k,1] for j,k in zip(r,c)]
        if(interp == 'rbf'):
            f = interpolate.Rbf(np.array(r).astype(float), np.array(c).astype(float), z,function='gaussian')
            X , Y = np.meshgrid(range(72),range(14))
            z_intp = f(X, Y)
            interp_noisy[i,:,:,1] = z_intp.T
        elif(interp == 'spline'):
            tck = interpolate.bisplrep(np.array(r).astype(float), np.array(c).astype(float), z)
            z_intp = interpolate.bisplev(range(72),range(14),tck)
            interp_noisy[i,:,:,1] = z_intp


    interp_noisy = np.concatenate((interp_noisy[:,:,:,0], interp_noisy[:,:,:,1]), axis=0).reshape(80000, 72, 14, 1)


    return interp_noisy

"""### Super Resulation Convolution Neural Network (model architecture)"""

def SRCNN_model():

    input_shape = (72,14,1)
    x = Input(shape = input_shape)
    c1 = Convolution2D( 64 , (9 , 9) , activation = 'relu', padding="same", kernel_initializer="he_normal")(x)
    c2 = Convolution2D( 32 , (1 , 1 ), activation = 'relu', padding="same", kernel_initializer="he_normal")(c1)
    c3 = Convolution2D( 1 , (5 , 5) , padding="same", kernel_initializer="he_normal")(c2)
    #c4 = Input(shape = input_shape)(c3)
    model = Model(inputs = x, outputs = c3)
    ##compile
    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)
    model.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])
    return model

"""### train model
#### batch size: 128
#### epochs: 20
"""

def SRCNN_train(train_data ,train_label, val_data , val_label , channel_model , num_pilots , SNR ):
    srcnn_model = SRCNN_model()
    print(srcnn_model.summary())

    checkpoint = ModelCheckpoint("SRCNN_check.h5", monitor='val_loss', verbose=1, save_best_only=True,
                                 save_weights_only=False, mode='min')
    callbacks_list = [checkpoint]

    srcnn_model.fit(train_data, train_label, batch_size=128, validation_data=(val_data, val_label),
                    callbacks=callbacks_list, shuffle=True, epochs= 20 , verbose=0)

    #srcnn_model.save_weights("drive/codes/my_srcnn/SRCNN_SUI5_weights/SRCNN_48_12.h5")
    srcnn_model.save_weights("SRCNN_" + channel_model +"_"+ str(num_pilots) + "_"  + str(SNR) + ".h5")

"""### Predict function for cnn model"""

def SRCNN_predict(input_data , channel_model , num_pilots , SNR):
    srcnn_model = SRCNN_model()
    #srcnn_model.load_weights("SRCNN_" + channel_model +"_"+ str(num_pilots) + "_"  + str(SNR) + ".h5")
    srcnn_model.load_weights('/content/drive/MyDrive/com_project_output/SRCNN_check.h5')
    predicted  = srcnn_model.predict(input_data)
    return predicted

"""### model architecture for denoising convolutional neural network"""

def DNCNN_model ():

    inpt = Input(shape=(None,None,1))
    # 1st layer, Conv+relu
    x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(inpt)
    x = Activation('relu')(x)
    # 18 layers, Conv+BN+relu
    for i in range(18):
        x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(x)
        x = BatchNormalization(axis=-1, epsilon=1e-3)(x)
        x = Activation('relu')(x)
    # last layer, Conv
    x = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1), padding='same')(x)
    x = Subtract()([inpt, x])   # input - noise
    model = Model(inputs=inpt, outputs=x)
    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)
    model.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])
    return model

"""### DNCNN train function"""

def DNCNN_train(train_data ,train_label, val_data , val_label, channel_model , num_pilots , SNR ):

  dncnn_model = DNCNN_model()
  print(dncnn_model.summary())

  checkpoint = ModelCheckpoint("DNCNN_check.h5", monitor='val_loss', verbose=1, save_best_only=True,
                               save_weights_only=False, mode='min')
  callbacks_list = [checkpoint]

  dncnn_model.fit(train_data, train_label, batch_size=128, validation_data=(val_data, val_label),
                  callbacks=callbacks_list, shuffle=True, epochs= 5 , verbose=0)
  dncnn_model.save_weights("DNCNN_" + channel_model +"_"+ str(num_pilots) + "_"  + str(SNR) + ".h5")

"""### DNCNN predict function"""

def DNCNN_predict(input_data, channel_model , num_pilots , SNR):
  dncnn_model = DNCNN_model()
  dncnn_model.load_weights("DNCNN_" + channel_model +"_"+ str(num_pilots) + "_"  + str(SNR) + ".h5")
  predicted  = dncnn_model.predict(input_data)
  return predicted

"""### initializing SNR, Number of pilot, Channel_model"""

SNR = 22
Number_of_pilots = 48
channel_model='VehA'
num_pilots=48

"""### spliting the data set into 90% train dataset and 10% validation dataset"""

interp_noisy = interpolation(noisy_input , SNR , Number_of_pilots , 'rbf')

perfect_image = np.zeros((len(perfect),72,14,2))
perfect_image[:,:,:,0] = np.real(perfect)
perfect_image[:,:,:,1] = np.imag(perfect)
perfect_image = np.concatenate((perfect_image[:,:,:,0], perfect_image[:,:,:,1]), axis=0).reshape(2*len(perfect), 72, 14, 1)


idx_random = np.random.rand(len(perfect_image)) < (1/9)  # uses 32000 from 36000 as training and the rest as validation
train_data, train_label = interp_noisy[idx_random,:,:,:] , perfect_image[idx_random,:,:,:]
val_data, val_label = interp_noisy[~idx_random,:,:,:] , perfect_image[~idx_random,:,:,:]

"""### Training CNN dataset"""

SRCNN_train(train_data ,train_label, val_data , val_label , channel_model , Number_of_pilots , SNR )

"""### shape of the input data for prediction"""

print(val_data.shape)
print(train_data.shape)
print(val_label.shape)
print(train_label.shape)

"""### prediction for CNN model"""

srcnn_pred_train = SRCNN_predict(train_data, channel_model , num_pilots , SNR)
#srcnn_pred_validation = SRCNN_predict(val_data, channel_model , num_pilots , SNR)

"""### converting the 4d array into pandas dataframe"""

import pandas as pd
mesh = pd.DataFrame(np.column_stack(list(map(np.ravel, np.meshgrid(*map(np.arange, srcnn_pred_validation.shape), indexing="ij"))) + [srcnn_pred_validation.ravel()]),
                   columns=["mode", "x", "y", "z", "val"])

val_pred_data_df = pd.DataFrame([index + (x,) for index, x in np.ndenumerate(srcnn_pred_validation)], columns=["mode", "x", "y", "z", "val"])
print(val_pred_data_df)

import pandas as pd
mesh = pd.DataFrame(np.column_stack(list(map(np.ravel, np.meshgrid(*map(np.arange, val_label.shape), indexing="ij"))) + [val_label.ravel()]),
                   columns=["mode", "x", "y", "z", "val"])

val_label_df = pd.DataFrame([index + (x,) for index, x in np.ndenumerate(val_label)], columns=["mode", "x", "y", "z", "val"])
print(val_label_df)

import pandas as pd
mesh = pd.DataFrame(np.column_stack(list(map(np.ravel, np.meshgrid(*map(np.arange, train_label.shape), indexing="ij"))) + [train_label.ravel()]),
                   columns=["mode", "x", "y", "z", "val"])

train_label_df = pd.DataFrame([index + (x,) for index, x in np.ndenumerate(train_label)], columns=["mode", "x", "y", "z", "val"])
print(train_label_df)

import pandas as pd
mesh = pd.DataFrame(np.column_stack(list(map(np.ravel, np.meshgrid(*map(np.arange, srcnn_pred_train.shape), indexing="ij"))) + [srcnn_pred_train.ravel()]),
                   columns=["mode", "x", "y", "z", "val"])

train_pred_data_df = pd.DataFrame([index + (x,) for index, x in np.ndenumerate(srcnn_pred_train)], columns=["mode", "x", "y", "z", "val"])
print(train_pred_data_df)

"""### Calculating the root mean square error (RMSE) for validation"""

y_actual=val_label_df['val']
y_hat=val_pred_data_df['val']

MSE = np.square(np.subtract(y_actual,y_hat)).mean()

RMSE = math.sqrt(MSE)

print(RMSE)

"""### calculating the min absolute percentage error(MAPE) for validation"""

mape = np.mean(np.abs((y_actual - y_hat)/y_actual))*100
print(mape)

print(psnr(y_hat,y_actual))

"""### Calculating the root mean square error (RMSE) for validation"""

y_actual=train_label_df['val']
y_hat=train_pred_data_df['val']

MSE = np.square(np.subtract(y_actual,y_hat)).mean()

RMSE = math.sqrt(MSE)

print(RMSE)

"""### calculating the min absolute percentage error(MAPE) for validation"""

mape = np.mean(np.abs((y_actual - y_hat)/y_actual))*100
print(mape)

"""### ploting the whole dataset in matplotlib"""

import matplotlib.pyplot as plt

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
x = noisy_input[:, 0]
y = noisy_input[:, 1]
z = noisy_input[:, 2]
ax.scatter(x, y, z, c=z)

plt.show()

"""### DNCNN train, validation and converting it to pandas dataframe"""

DNCNN_train(train_data ,train_label, val_data , val_label , channel_model , Number_of_pilots , SNR )

DNcnn_pred_train = DNCNN_predict(train_data, channel_model , num_pilots , SNR)
DNcnn_pred_validation = DNCNN_predict(val_data, channel_model , num_pilots , SNR)

mesh = pd.DataFrame(np.column_stack(list(map(np.ravel, np.meshgrid(*map(np.arange, train_data.shape), indexing="ij"))) + [train_data.ravel()]),
                   columns=["mode", "x", "y", "z", "val"])

train_data_df = pd.DataFrame([index + (x,) for index, x in np.ndenumerate(train_data)], columns=["mode", "x", "y", "z", "val"])
print(train_data_df)

train_data_path='/content/drive/MyDrive/com_project_output/train_data.xlsx'
df=pd.read_csv(train_data_path)

df

import pandas as pd

srcnn_pred_train_data_path='/content/drive/MyDrive/com_project_output/srcnn_pred_train.csv'
train_pred_df=pd.read_csv(srcnn_pred_train_data_path)

print(train_pred_df)

val_data_path='/content/drive/MyDrive/com_project_output/val_data.csv'
val_df=pd.read_csv(val_data_path)
print(val_df)

val_pred_data_path='/content/drive/MyDrive/com_project_output/srcnn_pred_validation.csv'
val_pred_df=pd.read_csv(val_pred_data_path)
print(val_pred_df)

import matplotlib.pyplot as plt

"""### plotting the actual vs predicted data"""

plt.figure(figsize=(10,10))
plt.scatter(y_actual, y_hat, c='crimson')
#plt.yscale('log')
#plt.xscale('log')

p1 = max(max(y_hat), max(y_actual))
p2 = min(min(y_hat), min(y_actual))
plt.plot([p1, p2], [p1, p2], 'b-')
plt.xlabel('True Values', color='blue',fontsize=15)
plt.ylabel('Predictions', color='red',fontsize=15)
plt.axis('equal')
plt.show()

"""### red indicates the auctual input validation data
### blue indicates the predicted validation data
"""

plt.subplot(1,2,1)
plt.plot(x,y_actual,color='red')
plt.subplot(1,2,2)
plt.plot(x,y_hat,color='blue')